# 변수 선택 및 분석 기법 정리

머신러닝에서 변수(Feature)는 데이터의 특징을 나타내는 중요한 요소입니다. RDBMS에서는 열(Column)이라고 부르지만, 머신러닝에서는 이를 변수(Feature)라고 합니다. 변수 선택은 모델의 성능을 향상시키고, 학습 속도를 높이며, 과적합을 방지하는 데 중요한 역할을 합니다. 이번 글에서는 변수 선택의 개념과 주요 기법을 정리해 보겠습니다.

## 변수의 유형
변수는 크게 **독립변수**와 **종속변수**로 나뉩니다.
- **독립변수(Explanatory Variable)**: 예측 변수, 회귀자, 통제 변수, 조작변수, 노출변수, 리스크 팩터, 설명변수, 입력변수 등으로 불립니다.
- **종속변수(Dependent Variable)**: 독립변수의 영향을 받아 변화하는 변수로, 예측해야 할 목표 변수(Target)입니다.

변수 선택 방법은 **지도 학습(Supervised Learning)**과 **비지도 학습(Unsupervised Learning)**으로 나뉩니다.
- **지도 학습**: 데이터의 레이블이 주어진 상태에서 학습을 진행합니다.
- **비지도 학습**: 레이블 없이 입력된 데이터를 기반으로 패턴을 학습하는 방식입니다.

변수 선택 기법에는 다음과 같은 방법이 있습니다.
- **필터(Filter) 기법**
- **래퍼(Wrapper) 기법**
- **임베디드(Embedded) 기법**

---

## 1. 필터(Filter) 기법
필터 기법은 데이터의 통계적 측정 방법을 사용하여 변수 간의 상관관계를 분석한 후, 높은 상관관계를 가지는 변수를 선택하는 방식입니다. 이 방식은 **계산 속도가 빠르고**, 변수 간 상관관계를 분석하는 데 적합하여 **래퍼 기법을 사용하기 전에 전처리 과정에서 활용**됩니다.

### 필터 기법 사례
- **정보이득(Information Gain)**: 전체 엔트로피에서 분류 후 엔트로피를 뺀 값으로, 불순도가 낮으면 정보 획득량이 높고, 정보 획득량이 높은 속성을 선택합니다.
- **카이제곱 검정(Chi-Square Test)**: 관찰된 빈도가 기대되는 빈도와 의미 있게 다른지를 검증하는 데 사용됩니다.
- **피셔 스코어(Fisher Score)**: 변수의 분포에 대해 유추할 수 있는 수치로, 뉴턴의 방법을 사용합니다.
- **상관계수(Correlation Coefficient)**: 두 변수 사이의 통계적 관계를 나타내는 계수입니다.

---

## 2. 래퍼(Wrapper) 기법
래퍼 기법에서는 변수를 선택하는 방법이 중요한 요소로 작용합니다. 이 방법은 **예측 정확도 측면에서 가장 좋은 성능을 보이는 변수의 하위 집합을 선택**하는 방식입니다.

래퍼 기법은 **그리디(Greedy) 알고리즘**을 사용하여 **반복적으로 변수를 선택하고 테스트**하는 방식이므로, 계산 비용이 높고 시간이 오래 걸릴 수 있습니다. 하지만 필터 기법보다 예측 정확도가 높다는 장점이 있습니다.

### 래퍼 기법의 변수 선택 방법
- **전진 선택법(Forward Selection)**: 모델의 성능을 가장 많이 향상시키는 변수를 하나씩 추가하는 방식입니다. 비어있는 상태에서 시작하며, 변수를 추가할 때 선택 기준이 향상되지 않으면 변수 추가를 중단합니다.
- **후진 소거법(Backward Elimination)**: 모든 변수를 포함한 상태에서 시작하여, 가장 적은 영향을 주는 변수부터 하나씩 제거하는 방식입니다. 더 이상 제거할 변수가 없다고 판단될 때 제거를 중단합니다.
- **단계적 방법(Stepwise Selection)**: 전진 선택과 후진 소거를 함께 사용하는 방식입니다.

---

## 3. 임베디드(Embedded) 기법
임베디드 기법은 **모델의 학습 과정에서 변수 선택이 이루어지는 방식**으로, 주어진 변수 중에서 모델의 정확도에 기여하는 변수를 자동으로 선택합니다.

### 임베디드 기법의 사례
- **라쏘(Lasso) Regression**: 가중치의 절댓값의 합을 최소화하는 것을 추가적인 제약 조건으로 하는 방법입니다. L1 노름 규제를 통해 제약을 줍니다.
- **릿지(Ridge) Regression**: 가중치들의 제곱 합을 최소화하는 것을 추가적인 제약 조건으로 하는 방법입니다. L2 노름 규제를 통해 제약을 줍니다.
- **엘라스틱 넷(Elastic Net)**: 라쏘와 릿지 두 가지를 결합한 방법으로, 가중치의 절댓값의 합과 제곱 합을 동시에 제약 조건으로 사용합니다.

---

## 4. 변수 선택 접근 방식
변수 선택 접근 방식은 여러 연구와 실무에서 활용되며, 데이터의 특성에 따라 적절한 방법을 선택하는 것이 중요합니다.

### 변수 선택 접근 방식의 유형
1. **분산에 따른 변수 선택(Variance Thresholding)**: 분산이 기준치보다 낮은 변수를 제거하는 방식입니다.
2. **단일 변수 선택(Univariate Selection)**: 각각의 변수를 하나만 사용했을 때 예측 모델의 성능을 평가하여, 정확도와 상관관계 등이 높은 변수를 선택하는 방식입니다.
3. **모델 기반 변수 선택(Model-Based Selection)**: 변수를 모델에 학습시킨 뒤, 특정 변수의 중요도가 기준치보다 높을 경우 선택하는 방식입니다.
4. **반복적 특성 선택(Recursive Feature Elimination, RFE)**: 변수들의 모든 조합을 시도해보고, 가장 좋은 성능을 보이는 변수를 선택하는 방식으로, 래퍼 기법과 관련이 있습니다.

---

## 마무리
변수 선택은 머신러닝 모델의 성능과 효율성을 높이는 중요한 과정입니다. 데이터의 특성과 분석 목적에 따라 **필터 기법, 래퍼 기법, 임베디드 기법** 중 적절한 방법을 선택하는 것이 중요합니다. 또한, 다양한 변수 선택 접근 방식을 활용하여 최적의 변수를 찾고, 모델의 성능을 극대화하는 것이 필요합니다.

변수 선택 기법을 잘 이해하고 적절히 활용한다면, 더 효과적인 머신러닝 모델을 구축할 수 있을 것입니다.
